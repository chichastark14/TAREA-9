{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtkvoeJxvteW",
    "outputId": "5fb79565-c959-42f2-8cb1-de0c84b69838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "LOHL208y0zeW",
    "outputId": "9221433c-46f1-4bc2-d8f6-83ad0ecdff6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jmmss\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "sgj_B7Vt076M"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "\n",
    "# La imagen que adoptará el estilo\n",
    "target_image_path = \"gato.jpg\"\n",
    "\n",
    "img = Image.open(target_image_path)\n",
    "img_width, img_height = img.size\n",
    "\n",
    "# La imagen que dará el estilo\n",
    "style_reference_image_path = \"Estilo.jpg\"\n",
    "\n",
    "# Dimensiones de la imagen generada\n",
    "width, height = load_img(target_image_path).size\n",
    "img_height = img_height\n",
    "img_width = img_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "b51HB5mB1RGW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import vgg19\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_height, img_width))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = x[:, :, ::-1]  # BGR -> RGB\n",
    "    x = np.clip(x, 0, 225).astype(\"float64\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Yks8NPL2CG-",
    "outputId": "632a6085-4447-4543-97d6-a45f8ba7644c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as k\n",
    "\n",
    "target_image = k.constant(preprocess_image(target_image_path))\n",
    "style_reference_image = k.constant(preprocess_image(style_reference_image_path))\n",
    "\n",
    "# Este marcador de posición contendrá nuestra imagen generada\n",
    "combination_image = k.placeholder((1, img_height, img_width, 3))\n",
    "\n",
    "# Combinamos las 3 imagenes en un solo lote\n",
    "input_tensor = k.concatenate([target_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)\n",
    "\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights= \"imagenet\",\n",
    "                    include_top=False)\n",
    "print(\"Modelo cargado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "cJwwPsel2bkd"
   },
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return k.sum(k.square(combination - base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "3RLBDIGp2eAG"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = k.batch_flatten(k.permute_dimensions(x, (2,0,1)))\n",
    "    gram = k.dot(features, k.transpose(features))\n",
    "    return gram\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_height * img_width\n",
    "    return k.sum(k.square(S-C)) / (4. * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "5ZJh6HUe2yHm"
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    a = k.square(\n",
    "        x[:, :img_height -1, :img_width -1, :] - x[:, 1:, :img_width -1, :])\n",
    "    b = k.square(\n",
    "        x[:, :img_height -1, :img_width -1, :] - x[:, :img_height -1, 1:, :])\n",
    "    return k.sum(k.pow(a+b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "x4cD3IZg3GB1"
   },
   "outputs": [],
   "source": [
    "# Crear un diccionario que asocia nombres de capas con sus salidas\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "# Nombre de la capa usada para la pérdida de contenido\n",
    "content_layer = \"block5_conv2\"\n",
    "\n",
    "# Nombre de las capas usadas para la pérdida de estilo\n",
    "style_layers = [\"block1_conv1\",\n",
    "                \"block2_conv1\",\n",
    "                \"block3_conv1\",\n",
    "                \"block4_conv1\",\n",
    "                \"block5_conv1\"]\n",
    "\n",
    "# Pesos para las diferentes pérdidas en el cálculo total\n",
    "total_variation_weight = 1e-4  # Peso para la pérdida de variación total\n",
    "style_weight = 1.0             # Peso para la pérdida de estilo\n",
    "content_weight = 0.025         # Peso para la pérdida de contenido\n",
    "\n",
    "# Inicializar la variable de pérdida total\n",
    "loss = k.variable(0.0)\n",
    "\n",
    "# Extraer características de la capa de contenido\n",
    "layer_features = outputs_dict[content_layer]\n",
    "target_image_features = layer_features[0, :, :, :]   # Características de la imagen objetivo\n",
    "combination_features = layer_features[2, :, :, :]    # Características de la imagen combinada\n",
    "loss = loss + content_weight * content_loss(target_image_features, combination_features)  # Añadir la pérdida de contenido a la pérdida total\n",
    "\n",
    "# Calcular y añadir la pérdida de estilo para cada capa de estilo\n",
    "for layer_name in style_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :]  # Características de la imagen de referencia de estilo\n",
    "    combination_features = layer_features[2, :, :, :]      # Características de la imagen combinada\n",
    "    sl = style_loss(style_reference_features, combination_features)  # Calcular la pérdida de estilo\n",
    "    loss += (style_weight / len(style_layers)) * sl        # Añadir la pérdida de estilo ponderada a la pérdida total\n",
    "\n",
    "# Añadir la pérdida de variación total a la pérdida total\n",
    "loss += total_variation_weight * total_variation_loss(combination_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "XLHE9vB243We",
    "outputId": "cbbbef4b-2c87-456a-a8d5-d20c51fb2b8f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Función para calcular la pérdida y los gradientes\n",
    "@tf.function\n",
    "def compute_loss_and_grads(image):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        loss = total_variation_weight * total_variation_loss(image)\n",
    "    grads = tape.gradient(loss, image)\n",
    "    return loss, grads\n",
    "\n",
    "# Clase Evaluator para evaluar la pérdida y los gradientes\n",
    "class Evaluator(object):\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "\n",
    "    # Método para calcular la pérdida\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        x = x.reshape((1, img_height, img_width, 3))\n",
    "        x_tensor = tf.convert_to_tensor(x)\n",
    "        loss_value, grad_values = compute_loss_and_grads(x_tensor)\n",
    "        self.loss_value = loss_value.numpy()\n",
    "        self.grad_values = grad_values.numpy().flatten().astype(\"float64\")\n",
    "        return self.loss_value\n",
    "\n",
    "    # Método para obtener los gradientes\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "# Dimensiones de la imagen\n",
    "img_height = 400\n",
    "img_width = 1846\n",
    "\n",
    "# Instancia de la clase Evaluator\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "LIFXnS8o6ASM",
    "outputId": "e7c9618e-daed-4df1-8529-e81e112550ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio de iteraciones 0\n",
      "Valos de perdida actual: 16798.581819593477\n",
      "Iteración 0 completa en 11s\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import imageio\n",
    "\n",
    "# Prefijo para los nombres de los archivos de resultado\n",
    "result_prefix = \"style_transfer_result\"\n",
    "# Número de iteraciones de optimización\n",
    "iterations = 1\n",
    "\n",
    "# Preprocesar la imagen de destino\n",
    "x = preprocess_image(target_image_path)\n",
    "# Aplanar la imagen preprocesada para la optimización\n",
    "x = x.flatten()\n",
    "# Bucle para realizar las iteraciones de optimización\n",
    "for i in range(iterations):\n",
    "    print(\"Inicio de iteraciones\", i)\n",
    "    start_time = time.time()  # Registrar el tiempo de inicio\n",
    "    # Ejecutar la optimización L-BFGS-B\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x,\n",
    "                                      fprime=evaluator.grads, maxfun=20)\n",
    "    print(\"Valos de perdida actual:\", min_val)\n",
    "\n",
    "    # Copiar y remodelar la imagen optimizada\n",
    "    img = x.copy().reshape((img_height, img_width, 3))\n",
    "    # Deshacer el preprocesamiento para obtener la imagen final\n",
    "    img = deprocess_image(img)\n",
    "    # Generar el nombre del archivo de resultado\n",
    "    fname = result_prefix + \"_at_iteration_%d.png\" % i\n",
    "    \n",
    "    # Guardar la imagen resultante\n",
    "    imageio.imwrite('Imagen generada.png', img)\n",
    "\n",
    "\n",
    "    end_time = time.time()  # Registrar el tiempo de finalización\n",
    "    print(\"Iteración %d completa en %ds\" % (i, end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[170.33752249, 136.24846544, 101.51468585],\n",
       "        [167.91257113, 133.7212046 ,  99.30661454],\n",
       "        [164.06197985, 129.80403166,  95.61315769],\n",
       "        ...,\n",
       "        [218.16342017, 174.16342115, 135.70574809],\n",
       "        [217.99516204, 173.99516301, 135.40440374],\n",
       "        [217.7294119 , 173.72941288, 134.99855021]],\n",
       "\n",
       "       [[170.32336046, 136.24251946, 101.56017764],\n",
       "        [168.15117192, 133.97714824,  99.63348677],\n",
       "        [164.46181985, 130.22858468,  96.114531  ],\n",
       "        ...,\n",
       "        [217.93626577, 173.93626675, 135.8175069 ],\n",
       "        [218.18300874, 174.18300972, 135.8883581 ],\n",
       "        [218.42628329, 174.42628427, 136.02067551]],\n",
       "\n",
       "       [[170.70014416, 136.65287001, 102.25103579],\n",
       "        [168.78468226, 134.65665258, 100.66778056],\n",
       "        [165.14574537, 130.97508817,  97.207322  ],\n",
       "        ...,\n",
       "        [218.1532539 , 174.15325488, 136.18010134],\n",
       "        [217.96257855, 173.96257952, 136.15908833],\n",
       "        [217.78449903, 173.78450001, 136.20669824]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 93.47907667,  80.38566458,  77.82846095],\n",
       "        [ 93.46012393,  80.36466991,  77.82847513],\n",
       "        [ 93.32616804,  80.24543025,  77.65349954],\n",
       "        ...,\n",
       "        [ 88.19103738,  70.98343729,  67.78027565],\n",
       "        [ 86.69253009,  69.61844484,  66.22702671],\n",
       "        [ 86.8124835 ,  69.85717708,  65.46478099]],\n",
       "\n",
       "       [[ 80.71595367,  67.79078335,  65.48944118],\n",
       "        [ 80.64985225,  67.73686436,  65.40809901],\n",
       "        [ 80.43857913,  67.56160839,  65.15950259],\n",
       "        ...,\n",
       "        [ 77.03242294,  60.40501019,  57.39344434],\n",
       "        [ 72.09628764,  55.92045381,  53.80300973],\n",
       "        [ 64.46794509,  48.82297789,  47.48723286]],\n",
       "\n",
       "       [[ 75.07119211,  61.63011459,  58.06023899],\n",
       "        [ 74.99906364,  61.57467856,  57.95156746],\n",
       "        [ 74.91853198,  61.507533  ,  57.8788282 ],\n",
       "        ...,\n",
       "        [ 72.49451072,  56.30300889,  53.33203972],\n",
       "        [ 64.77436909,  49.13896521,  48.26064337],\n",
       "        [ 32.99999969,  21.00000067,  30.99999701]]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
